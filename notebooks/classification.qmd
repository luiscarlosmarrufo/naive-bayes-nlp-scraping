---
title: "Clasificación"
author: "Equipo 1"
format: html
editor: visual
---

```{r}
library(textdata)
library(tidyverse)
library(tidytext)
library(dplyr)
library(stringr)
library(Matrix)

library(tidymodels) 
library(e1071)
library(naivebayes)
library(slam)
library(caret)
```

```{r}
data <- read_csv("../data/stories.csv")
head(data)
```

```{r}
clean_txt <- function(x) {
  x %>%
    str_to_lower() %>%
    str_replace_all("\\n", " ") %>%
    str_replace_all("[^a-z ]", " ") %>%
    str_squish()
}
```

```{r}
data <- data %>%
  mutate(
    doc_id = row_number(),
    description_clean = clean_txt(description)
  )

head(data)
```

Tokenizacion y quitar stop words

```{r}
tokens <- data %>%
  select(doc_id, category, description_clean) %>%
  unnest_tokens(word, description_clean) %>%
  anti_join(stop_words, by = "word") %>%
  filter(nchar(word) > 1)
```

```{r}
tokens
```

```{r}
nrc <- get_sentiments("nrc")
```

```{r}
sentiment_analysis <- tokens %>%
  inner_join(nrc, by = "word") %>%
  count(doc_id, sentiment) %>%   
  tidyr::spread(sentiment, n, fill = 0)
```

```{r}
sentiment_analysis
```

```{r}
doc_term_counts <- tokens %>%
  count(doc_id, word, name = "n", sort = FALSE)

doc_term_counts
```

Sparse matrix

```{r}
X_dtm <- doc_term_counts %>%
  cast_sparse(row = doc_id, column = word, value = n)

dim(X_dtm)
```

```{r}
term_freq <- slam::col_sums(X_dtm)

# Filtrar términos con frecuencia >= 10
X_dtm_filtrado <- X_dtm[, term_freq >= 10]
```

```{r}
X_dtm_filtrado
```

```{r}
as.data.frame(table(data$category))
```

Ya que "Haunted Places" tiene un 40% de los datos por su cuenta, se dicotomizará utilizando "Haunted Places" u "Others".

```{r}
dtm <- as.data.frame(as.matrix(X_dtm_filtrado))
```

```{r}
df_x <- cbind(
  dtm,
  sentiment_analysis,
  place = data$state
)
```

```{r}
y <- as.factor(data$category)
```

```{r}
set.seed(1310)

train_index <- sample(1:nrow(df_x), 0.7 * nrow(df_x))

train_x <- df_x[train_index, ]
test_x <- df_x[-train_index, ]

train_y <- y[train_index]
test_y <- y[-train_index]

model_e1071 <- naiveBayes(train_x, train_y)
```

```{r}
pred <- predict(model_e1071, test_x)
caret::confusionMatrix(pred, test_y)
```

```{r}
model_NB <- naive_bayes(train_x, train_y)
```
```{r}
pred2 <- predict(model_NB, test_x)
caret::confusionMatrix(pred2, test_y)
```

```{r}

```


