---
title: "Clasificación"
author: "Equipo 1"
format: html
editor: visual
---

```{r}
library(textdata)
library(tidyverse)
library(tidytext)
library(dplyr)
library(stringr)
library(Matrix)

library(tidymodels) 
library(e1071)
library(naivebayes)
library(slam)
library(caret)
```

```{r}
data <- read_csv("../data/stories.csv")
head(data)
```

```{r}
clean_txt <- function(x) {
  x %>%
    str_to_lower() %>%
    str_replace_all("\\n", " ") %>%
    str_replace_all("[^a-z ]", " ") %>%
    str_squish()
}
```

```{r}
data <- data %>%
  mutate(
    doc_id = row_number(),
    description_clean = clean_txt(description)
  )

head(data)
```

Tokenizacion y quitar stop words

```{r}
tokens <- data %>%
  select(doc_id, category, description_clean) %>%
  unnest_tokens(word, description_clean) %>%
  anti_join(stop_words, by = "word") %>%
  filter(nchar(word) > 1)
```

```{r}
tokens
```

```{r}
nrc <- get_sentiments("nrc")
afinn <- get_sentiments("afinn")
```

```{r}
sentiment_analysis <- tokens %>%
  inner_join(nrc, by = "word") %>%
  count(doc_id, sentiment) %>%   
  tidyr::spread(sentiment, n, fill = 0)
```

```{r}
sentiment_analysis

```

```{r}
doc_term_counts <- tokens %>%
  count(doc_id, word, name = "n", sort = FALSE)

doc_term_counts
```

Sparse matrix

```{r}
X_dtm <- doc_term_counts %>%
  cast_sparse(row = doc_id, column = word, value = n)

dim(X_dtm)
```

```{r}
term_freq <- slam::col_sums(X_dtm)

# Filtrar términos con frecuencia >= 10
X_dtm_filtrado <- X_dtm[, term_freq >= 10]
```

```{r}
#X_dtm_filtrado
```

```{r}
as.data.frame(table(data$category))
```

Ya que "Haunted Places" tiene un 40% de los datos por su cuenta, se dicotomizará utilizando "Haunted Places" u "Others".

```{r}
dtm <- as.data.frame(as.matrix(X_dtm_filtrado))
```

```{r}
all_ids <- data.frame(doc_id = 1:nrow(X_dtm_filtrado))

sentiment_analysis_afinn <- tokens %>%
  inner_join(afinn, by = "word") %>%
  group_by(doc_id) %>%
  summarise(sentiment_score = sum(value, na.rm = TRUE)) %>%
  right_join(all_ids, by = "doc_id") %>%
  mutate(sentiment_score = ifelse(is.na(sentiment_score), 0, sentiment_score))

```

```{r}
# df final tomando frecuencia de palabras, análisis de sentimiento y el estado.

df_x <- cbind(
  dtm,
  sentiment_analysis,
  place = data$state
)
```

```{r}
df_x_afinn <- cbind(
  dtm,
  sentiment_analysis_afinn,
  place = data$state
)
```

```{r}
#head(df_x)
```

```{r}
head(df_x_afinn)
```

```{r}
y <- as.factor(data$category)
```

```{r}
set.seed(1310)

train_index <- sample(1:nrow(df_x), 0.7 * nrow(df_x))

train_x <- df_x[train_index, ]
test_x <- df_x[-train_index, ]

train_y <- y[train_index]
test_y <- y[-train_index]

model_e1071 <- naiveBayes(train_x, train_y)
```

```{r}
pred <- predict(model_e1071, test_x)
caret::confusionMatrix(pred, test_y)
```

```{r}
model_NB <- naive_bayes(train_x, train_y)
```

```{r}
pred2 <- predict(model_NB, test_x)
caret::confusionMatrix(pred2, test_y)
```

```{r}

y_bin = case_when(
  y == "Haunted Places" ~ "Haunted Places",
  TRUE ~ "Other"
  )
```

```{r}
y_bin <- as.factor(y_bin)
```

```{r}
train_x <- df_x[train_index, ]
test_x <- df_x[-train_index, ]

train_y <- y_bin[train_index]
test_y <- y_bin[-train_index]
```

```{r}
model_e1071 <- naiveBayes(train_x, train_y)
model_NB <- naive_bayes(train_x, train_y)
```

```{r}
pred_e1071 <- predict(model_e1071, test_x)
pred_NB <- predict(model_NB, test_x)
```

```{r}
caret::confusionMatrix(pred_e1071, test_y)
```

```{r}
caret::confusionMatrix(pred_NB, test_y)
```

```{r}
# Distribución Poisson
model_poisson_nb <- naive_bayes(train_x, train_y, usepoisson = TRUE)
pred_poisson <- predict(model_poisson_nb, test_x)
caret::confusionMatrix(pred_poisson, test_y)
```

```{r}
library(naivebayes)
library(caret)
# Suavizar
alpha <- 1
model_poisson_nb_smooth <- naive_bayes(x = train_x, y = train_y, laplace = alpha)
pred_poisson_smooth <- predict(model_poisson_nb_smooth, newdata = test_x)

caret::confusionMatrix(pred_poisson_smooth, test_y)
```

Todos los alphas son iguales y siempre selecciona el 0, ya basta. Eliminé los Kfolds zzz sigue todo igual. Buscamos otra técnica de suavizamiento para lidiar con los 0: Binarizar es la q sirvio ligeramente mejor que laplace\*\*\*\*\*\*

```{r}
# Binarizar
x_tr <- (train_x > 0) * 1
x_te <- (test_x  > 0) * 1
mdl  <- naivebayes::naive_bayes(x = x_tr, y = train_y)
pred_bi <- predict(mdl, x_te)
```

```{r}
caret::confusionMatrix(pred_bi, test_y)
```

afinn

```{r}
set.seed(1310)

train_index_afinn <- sample(1:nrow(df_x_afinn), 0.7 * nrow(df_x_afinn))

train_x_afinn <- df_x_afinn[train_index_afinn, ]
test_x_afinn  <- df_x_afinn[-train_index_afinn, ]

train_y <- y[train_index_afinn]
test_y  <- y[-train_index_afinn]

```

```{r}
model_e1071_afinn <- naiveBayes(train_x_afinn, train_y)
pred_e1071_afinn  <- predict(model_e1071_afinn, test_x_afinn)
caret::confusionMatrix(pred_e1071_afinn, test_y)
```

```{r}
model_NB_afinn <- naive_bayes(train_x_afinn, train_y)
pred_NB_afinn  <- predict(model_NB_afinn, test_x_afinn)
caret::confusionMatrix(pred_NB_afinn, test_y)
```

```{r}
y_bin <- dplyr::case_when(
  y == "Haunted Places" ~ "Haunted Places",
  TRUE ~ "Other"
)
y_bin <- as.factor(y_bin)

train_yb <- y_bin[train_index_afinn]
test_yb  <- y_bin[-train_index_afinn]
```

```{r}
model_e1071_bin_afinn <- naiveBayes(train_x_afinn, train_yb)
model_NB_bin_afinn    <- naive_bayes(train_x_afinn, train_yb)

pred_e1071_bin_afinn <- predict(model_e1071_bin_afinn, test_x_afinn)
pred_NB_bin_afinn    <- predict(model_NB_bin_afinn, test_x_afinn)

caret::confusionMatrix(pred_e1071_bin_afinn, test_yb)
caret::confusionMatrix(pred_NB_bin_afinn,    test_yb)
```

```{r}
model_poisson_nb_afinn <- naive_bayes(train_x_afinn, train_yb, usepoisson = TRUE)
pred_poisson_afinn     <- predict(model_poisson_nb_afinn, test_x_afinn)
caret::confusionMatrix(pred_poisson_afinn, test_yb)
```

```{r}
alpha <- 1
model_poisson_nb_smooth_afinn <- naive_bayes(x = train_x_afinn, y = train_yb, laplace = alpha)
pred_poisson_smooth_afinn     <- predict(model_poisson_nb_smooth_afinn, newdata = test_x_afinn)
caret::confusionMatrix(pred_poisson_smooth_afinn, test_yb)

```

```{r}
x_tr_afinn <- (train_x_afinn > 0) * 1
x_te_afinn <- (test_x_afinn  > 0) * 1

mdl_bi_afinn  <- naivebayes::naive_bayes(x = x_tr_afinn, y = train_yb)
pred_bi_afinn <- predict(mdl_bi_afinn, x_te_afinn)
caret::confusionMatrix(pred_bi_afinn, test_yb)
```
